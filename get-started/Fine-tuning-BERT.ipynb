{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf541a3",
   "metadata": {},
   "source": [
    "# BERT Fine-tuning on IPU\n",
    "\n",
    "This notebook will demonstrate how to fine-tune a pre-trained BERT model with PyTorch on the Graphcore IPU-POD16 system. We will use a BERT-Large model and fine-tune on the SQuADv1 Question/Answering task.\n",
    "\n",
    "We will show how to take a BERT model written in PyTorch from the ğŸ¤—`transformers` library from HuggingFace and parallelize and run it on IPU using PopTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81f9be",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "- Paperspace account with access to the PyTorch IPU runtime\n",
    "- Python packages in requirements.txt, installed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268612c8-351f-4686-be79-6c830946fd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:25.123362Z",
     "iopub.status.busy": "2022-08-04T18:52:25.123131Z",
     "iopub.status.idle": "2022-08-04T18:52:27.622074Z",
     "shell.execute_reply": "2022-08-04T18:52:27.621093Z",
     "shell.execute_reply.started": "2022-08-04T18:52:25.123289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.2.1)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.1\n",
      "    Uninstalling pip-22.2.1:\n",
      "      Successfully uninstalled pip-22.2.1\n",
      "Successfully installed pip-22.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e087c904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:27.623573Z",
     "iopub.status.busy": "2022-08-04T18:52:27.623371Z",
     "iopub.status.idle": "2022-08-04T18:52:42.590436Z",
     "shell.execute_reply": "2022-08-04T18:52:42.589441Z",
     "shell.execute_reply.started": "2022-08-04T18:52:27.623552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: jedi==0.17.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (0.17.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (4.64.0)\n",
      "Collecting transformers==4.10.2\n",
      "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from jedi==0.17.2->-r requirements.txt (line 2)) (0.7.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m768.2/768.2 kB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.2->-r requirements.txt (line 4)) (5.4.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.10.2->-r requirements.txt (line 4)) (2.22.0)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.2->-r requirements.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter->-r requirements.txt (line 1)) (6.5.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter->-r requirements.txt (line 1)) (7.7.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter->-r requirements.txt (line 1)) (5.5.6)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter->-r requirements.txt (line 1)) (6.4.12)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter->-r requirements.txt (line 1)) (6.4.4)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.8/dist-packages (from jupyter->-r requirements.txt (line 1)) (5.3.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py38-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.2->-r requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.10.2->-r requirements.txt (line 4)) (3.0.9)\n",
      "Collecting urllib3>=1.25.10\n",
      "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (22.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (7.16.3)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (7.3.4)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (6.2)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (3.0.30)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (2.12.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (4.11.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (4.11.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.6.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (5.4.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->-r requirements.txt (line 1)) (1.5.5)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->-r requirements.txt (line 1)) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->-r requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->-r requirements.txt (line 1)) (0.15.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2022.1)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from qtconsole->jupyter->-r requirements.txt (line 1)) (2.1.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers==4.10.2->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 1)) (45.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 1)) (2.16.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->-r requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets->-r requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 1)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 1)) (0.18.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 1)) (3.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895255 sha256=6c719587bf47a95e35b2755fbda72050660f103f0a8fdd96e5b564078c409261\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, xxhash, urllib3, regex, numpy, multidict, joblib, fsspec, frozenlist, filelock, dill, click, charset-normalizer, async-timeout, yarl, sacremoses, responses, pyarrow, pandas, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 charset-normalizer-2.1.0 click-8.1.3 datasets-2.4.0 dill-0.3.5.1 filelock-3.7.1 frozenlist-1.3.1 fsspec-2022.7.1 huggingface-hub-0.8.1 joblib-1.1.0 multidict-6.0.2 multiprocess-0.70.13 numpy-1.23.1 pandas-1.4.3 pyarrow-9.0.0 regex-2022.7.25 responses-0.18.0 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.10.2 urllib3-1.26.11 xxhash-3.0.0 yarl-1.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86a3e1",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "BERT fine-tuning is when you train a BERT model on a supervised learning task on a relatively small amount of data, by using starting weights obtained from pre-training on a large, generic text corpus. Pre-training of BERT requires a lot of unlabelled data (for instance all of Wikipedia + thousands of books) and a lot of compute. It is expensive and time-consuming, but after pre-training BERT will have learned an extremely good language model that can be fine-tuned on downstream tasks with small amount of labeled data, achieving great results.\n",
    "\n",
    "![bert.png](static/bert.png)\n",
    "\n",
    "In this notebook we will fine-tune BERT (pre-trained on IPU with the Wikipedia dataset) on a question answering task called SQuAD. Then we will perform inference on the accompanying validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a67b1a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:42.592386Z",
     "iopub.status.busy": "2022-08-04T18:52:42.592196Z",
     "iopub.status.idle": "2022-08-04T18:52:44.143215Z",
     "shell.execute_reply": "2022-08-04T18:52:44.142412Z",
     "shell.execute_reply.started": "2022-08-04T18:52:42.592364Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Import standard packages\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from datasets import load_dataset, load_metric\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# To run on IPU we import popart and poptorch packages\n",
    "import popart\n",
    "import poptorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ba25ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:44.144833Z",
     "iopub.status.busy": "2022-08-04T18:52:44.144526Z",
     "iopub.status.idle": "2022-08-04T18:52:44.147632Z",
     "shell.execute_reply": "2022-08-04T18:52:44.147071Z",
     "shell.execute_reply.started": "2022-08-04T18:52:44.144813Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef0f5b",
   "metadata": {},
   "source": [
    "## 1. Get the data\n",
    "\n",
    "\n",
    "**What is SQuAD?**\n",
    "\n",
    "> Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n",
    "\n",
    "From https://rajpurkar.github.io/SQuAD-explorer/\n",
    "\n",
    "Basically you train a model to take a question and read a passage of text and predict the start and end positions of where that answer lies in the passage. The image below shows an example from the dataset:\n",
    "\n",
    "![squad.png](static/squad.png)\n",
    "\n",
    "(Source: [Rajpurkar GitHub](https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/Normans.html))\n",
    "\n",
    "For the case of SQuADv1 there are no unanswerable questions in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd1032",
   "metadata": {},
   "source": [
    "We use the ğŸ¤— `datasets` package to automatically download the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9370c3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:44.148464Z",
     "iopub.status.busy": "2022-08-04T18:52:44.148283Z",
     "iopub.status.idle": "2022-08-04T18:52:53.842696Z",
     "shell.execute_reply": "2022-08-04T18:52:53.841898Z",
     "shell.execute_reply.started": "2022-08-04T18:52:44.148445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73d1cf97245467db057e419d75e999e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c3e0859d1049a1b51412875608abf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.torch/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b29e8ddc3ca4f06bc67a4958ddeefb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5d3e4dcba44626afa0ea50d47b5225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4103dab03e5b4fcbbf235387c791b19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04191c6f3cb541efa755a0e18ced1354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985bc6ee7cc84564933ded7631608a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c89a927cc4d43afa09f7a6890567cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /root/.torch/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302fc33679d9449d9d2c4f2d4e225cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"squad\", cache_dir=Path.home() / \".torch/datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b36d9",
   "metadata": {},
   "source": [
    "The SQuAD dataset consists of pre-defined training and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7e37f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:53.844026Z",
     "iopub.status.busy": "2022-08-04T18:52:53.843832Z",
     "iopub.status.idle": "2022-08-04T18:52:53.852031Z",
     "shell.execute_reply": "2022-08-04T18:52:53.851280Z",
     "shell.execute_reply.started": "2022-08-04T18:52:53.843992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fd2a6",
   "metadata": {},
   "source": [
    "Each row in the data consists of a passage of text - `context` - a question about the passage - `question` - and the answer(s) to the question - `answers`. The latter consists of the text in the passage and the start position in the text.\n",
    "\n",
    "Here is an example row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf6e1e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:53.853036Z",
     "iopub.status.busy": "2022-08-04T18:52:53.852866Z",
     "iopub.status.idle": "2022-08-04T18:52:53.857366Z",
     "shell.execute_reply": "2022-08-04T18:52:53.856765Z",
     "shell.execute_reply.started": "2022-08-04T18:52:53.853020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56de5ef44396321400ee2861',\n",
       " 'title': 'Institute_of_technology',\n",
       " 'context': 'Institutes of technology in Venezuela were developed in the 1950s as an option for post-secondary education in technical and scientific courses, after the polytechnic French concepts. At that time, technical education was considered essential for the development of a sound middle class economy.',\n",
       " 'question': 'What type of economy was technical education in Venezuela intended to support?',\n",
       " 'answers': {'text': ['middle class'], 'answer_start': [274]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][10016]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609df4f",
   "metadata": {},
   "source": [
    "**How do we preprocess this data to train it with a deep learning model?**\n",
    "\n",
    "We need to `tokenize` the text to turn it from words into numbers. This is done using `transformers.BertTokenizer`. Let's use this to tokenize a shortened version of the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53cea07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:53.859694Z",
     "iopub.status.busy": "2022-08-04T18:52:53.859528Z",
     "iopub.status.idle": "2022-08-04T18:52:54.998276Z",
     "shell.execute_reply": "2022-08-04T18:52:54.997507Z",
     "shell.execute_reply.started": "2022-08-04T18:52:53.859678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d6bef4e10745359024171297059443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad51fa7e044c4ba488b9ba74e19a019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f759e45b03a43c092b10e51568c551c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a5b5745f12434c8adb81d943ad20b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from squad_preprocessing import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cf08b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:55.001475Z",
     "iopub.status.busy": "2022-08-04T18:52:55.001299Z",
     "iopub.status.idle": "2022-08-04T18:52:55.028219Z",
     "shell.execute_reply": "2022-08-04T18:52:55.027244Z",
     "shell.execute_reply.started": "2022-08-04T18:52:55.001457Z"
    }
   },
   "outputs": [],
   "source": [
    "example = {\"context\": \"Institutes of technology in Venezuela were developed in the 1950s\",\n",
    "           \"question\": \"When were Institutes of technology developed?\"}\n",
    "tokenized_example = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=32,\n",
    "        stride=16,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9e5b959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:55.030791Z",
     "iopub.status.busy": "2022-08-04T18:52:55.030625Z",
     "iopub.status.idle": "2022-08-04T18:52:55.034688Z",
     "shell.execute_reply": "2022-08-04T18:52:55.034052Z",
     "shell.execute_reply.started": "2022-08-04T18:52:55.030773Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b095905",
   "metadata": {},
   "source": [
    "Let's look at the `input_ids`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdec5710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:55.036813Z",
     "iopub.status.busy": "2022-08-04T18:52:55.036655Z",
     "iopub.status.idle": "2022-08-04T18:52:55.040635Z",
     "shell.execute_reply": "2022-08-04T18:52:55.040089Z",
     "shell.execute_reply.started": "2022-08-04T18:52:55.036798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2043,\n",
       " 2020,\n",
       " 12769,\n",
       " 1997,\n",
       " 2974,\n",
       " 2764,\n",
       " 1029,\n",
       " 102,\n",
       " 12769,\n",
       " 1997,\n",
       " 2974,\n",
       " 1999,\n",
       " 8326,\n",
       " 2020,\n",
       " 2764,\n",
       " 1999,\n",
       " 1996,\n",
       " 4856,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example.input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8257474d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:55.042795Z",
     "iopub.status.busy": "2022-08-04T18:52:55.042637Z",
     "iopub.status.idle": "2022-08-04T18:52:55.046403Z",
     "shell.execute_reply": "2022-08-04T18:52:55.045885Z",
     "shell.execute_reply.started": "2022-08-04T18:52:55.042780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] when were institutes of technology developed? [SEP] institutes of technology in venezuela were developed in the 1950s [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_example.input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f538e0e",
   "metadata": {},
   "source": [
    "As you can see in the decoded version, the question is placed at the start followed by a `[SEP]` token, then the context, followed by padding if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55f5b978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:55.048494Z",
     "iopub.status.busy": "2022-08-04T18:52:55.048334Z",
     "iopub.status.idle": "2022-08-04T18:52:55.051125Z",
     "shell.execute_reply": "2022-08-04T18:52:55.050504Z",
     "shell.execute_reply.started": "2022-08-04T18:52:55.048479Z"
    }
   },
   "outputs": [],
   "source": [
    "from squad_preprocessing import prepare_train_features, prepare_validation_features, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe8b3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:52:55.053350Z",
     "iopub.status.busy": "2022-08-04T18:52:55.053193Z",
     "iopub.status.idle": "2022-08-04T18:53:54.774625Z",
     "shell.execute_reply": "2022-08-04T18:53:54.773832Z",
     "shell.execute_reply.started": "2022-08-04T18:52:55.053335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afef176069c4f03ac88dc1f17f43c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882cd72c46424e71b90887832bfcbae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=datasets[\"train\"].column_names,\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "\n",
    "# Create validation features from dataset\n",
    "validation_features = datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=datasets[\"validation\"].column_names,\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f16832",
   "metadata": {},
   "source": [
    "## 2. Get the Model and Parallelize on IPU-POD16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595aec5",
   "metadata": {},
   "source": [
    "We run the model on IPU using both **pipelining** and **data parallelism** in order to maximise hardware use.\n",
    "\n",
    "### Parallelism through pipelining\n",
    "\n",
    "The model layers are split over 8 IPUs. We then use [*pipeline parallelism*](https://docs.graphcore.ai/projects/tf-model-parallelism/en/latest/pipelining.html) over the IPUs with gradient accumulation. We subdivide the compute batch into micro-batches that pass through the pipeline in the forward pass and then come back again in the backwards pass, accumulating gradients for the parameters as they go.\n",
    "\n",
    "A complete pipeline step has a ramp-up phase the start and a ramp-down phase at the end. Increasing the gradient accumulation factor, increases the total batch size and also increases the pipeline efficiency, and therefore throughput, because the proportion of time in ramp-up/down phases will be reduced. \n",
    "\n",
    "![pipelining.png](static/pipelining.png)\n",
    "\n",
    "### Partitioning the Model\n",
    "\n",
    "BERT Large has 24 transformer layers, which we will split over our 8 IPUs. The embeddings, MLM projection layers, and the first 2 transformer layers sit on IPU0, the following 6 IPUs have 3 transformer layers each, and the last IPU has 4.\n",
    "\n",
    "![partitioning.jpg](static/partitioning.jpg)\n",
    "\n",
    "### Data Parallelism\n",
    "\n",
    "An IPU-POD16 contains 16 IPUs and our pipeline is 8 IPUs long. We can therefore replicate the pipeline, feeding two different micro-batches to the device, which doubles the effective mini-batch size. We call this configuration a \"2x8 pipeline\".\n",
    "\n",
    "\n",
    "### Recomputation Checkpoints\n",
    "\n",
    "We can make more efficient use of the valuable In-Processor-Memory by saving only selected activation inputs and recomputing the rest. This lets us optimise on memory savings (by not storing all activations) vs FLOP expenditure (by not having to recompute all activations). \n",
    "![recomputation.png](static/recomputation.png)\n",
    "Source: [TensorFlow Model Parallelism: Recomputation](https://docs.graphcore.ai/projects/tf-model-parallelism/en/latest/pipelining.html#recomputation)\n",
    "\n",
    "Checkpoints are automatically placed between each pipeline stage. In addition to these automatic checkpoints, we are adding one at the end of every transformer layer, which leads to better performance.\n",
    "\n",
    "### Replicated Tensor Sharding of Optimizer State\n",
    "\n",
    "As we are using multiple replicas (2 here), we can also distribute our optimizer state to reduce local memory usage, a method called [On-chip Replicated Tensor Sharding (RTS)](https://docs.graphcore.ai/projects/graphcore-glossary/en/latest/index.html#term-Replicated-tensor-sharding).\n",
    "\n",
    "> To further improve memory availability we also have the option to store tensors in the POD-IPU16 Streaming Memory at the cost of increased communications.\n",
    "\n",
    "![rts.png](static/rts.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2fb3a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:53:54.777092Z",
     "iopub.status.busy": "2022-08-04T18:53:54.776818Z",
     "iopub.status.idle": "2022-08-04T18:53:54.780901Z",
     "shell.execute_reply": "2022-08-04T18:53:54.780445Z",
     "shell.execute_reply.started": "2022-08-04T18:53:54.777072Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function marks a PyTorch layer as a recomputation checkpoint\n",
    "def checkpoint_outputs(module: nn.Module):\n",
    "    \"\"\"Annotates the output of a module to be checkpointed instead of\n",
    "        recomputed\"\"\"\n",
    "    def recompute_outputs(module, inputs, outputs):\n",
    "        return tuple(poptorch.recomputationCheckpoint(y) for y in outputs)\n",
    "    module.register_forward_hook(recompute_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e541eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:53:54.788399Z",
     "iopub.status.busy": "2022-08-04T18:53:54.788131Z",
     "iopub.status.idle": "2022-08-04T18:53:54.806117Z",
     "shell.execute_reply": "2022-08-04T18:53:54.805677Z",
     "shell.execute_reply.started": "2022-08-04T18:53:54.788382Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_layer_ipu(layers_per_ipu):\n",
    "    # List of the IPU Id for each encoder layer\n",
    "    layer_ipu = []\n",
    "    for ipu, n_layers in enumerate(layers_per_ipu):\n",
    "        layer_ipu += [ipu] * n_layers\n",
    "    return layer_ipu\n",
    "\n",
    "\n",
    "# Subclass the HuggingFace BERTForQuestionAnswering model\n",
    "class PipelinedBertForQuestionAnswering(transformers.BertForQuestionAnswering):\n",
    "    def parallelize(self, ipu_config):\n",
    "        layer_ipu = get_layer_ipu(ipu_config[\"layers_per_ipu\"])\n",
    "        print(\"-------------------- Device Allocation --------------------\")\n",
    "        print(\"Embedding  --> IPU 0\")\n",
    "        self.bert.embeddings = poptorch.BeginBlock(self.bert.embeddings, \"Embedding\", ipu_id=0)\n",
    "\n",
    "        for index, layer in enumerate(self.bert.encoder.layer):\n",
    "            ipu = layer_ipu[index]\n",
    "            if index != self.config.num_hidden_layers - 1:\n",
    "                checkpoint_outputs(layer)\n",
    "            self.bert.encoder.layer[index] = poptorch.BeginBlock(layer, f\"Encoder{index}\", ipu_id=ipu)\n",
    "            print(f\"Encoder {index:<2} --> IPU {ipu}\")\n",
    "\n",
    "        print(f\"QA Outputs --> IPU {ipu}\")\n",
    "        self.qa_outputs = poptorch.BeginBlock(self.qa_outputs, \"QA Outputs\", ipu_id=ipu)\n",
    "        return self\n",
    "\n",
    "    # Model training loop is entirely running on IPU so we add Loss computation here\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, start_positions=None, end_positions=None):\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            \"start_positions\": start_positions,\n",
    "            \"end_positions\": end_positions\n",
    "        }\n",
    "        output = super().forward(**inputs)\n",
    "        if self.training:\n",
    "            final_loss = poptorch.identity_loss(output.loss, reduction=\"none\")\n",
    "            return final_loss, output.start_logits, output.end_logits\n",
    "        else:\n",
    "            return output.start_logits, output.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42eb7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:53:54.808242Z",
     "iopub.status.busy": "2022-08-04T18:53:54.807979Z",
     "iopub.status.idle": "2022-08-04T18:53:54.811208Z",
     "shell.execute_reply": "2022-08-04T18:53:54.810754Z",
     "shell.execute_reply.started": "2022-08-04T18:53:54.808225Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERT-Large configuration\n",
    "config = transformers.BertConfig(hidden_size=1024,\n",
    "                                 intermediate_size=1024*4,\n",
    "                                 num_hidden_layers=24,\n",
    "                                 num_attention_heads=16,\n",
    "                                 hidden_dropout_prob=0.15,\n",
    "                                 attention_probs_dropout_prob=0.1,\n",
    "                                 layer_norm_eps=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01344667",
   "metadata": {},
   "source": [
    "Model is still on CPU at this point. We can use `from_pretrained` to load pretrained checkpoints from the HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "675ddbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:53:54.813558Z",
     "iopub.status.busy": "2022-08-04T18:53:54.813277Z",
     "iopub.status.idle": "2022-08-04T18:54:08.834548Z",
     "shell.execute_reply": "2022-08-04T18:54:08.833904Z",
     "shell.execute_reply.started": "2022-08-04T18:53:54.813541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bce4ec0d2a42feb98230b80b35dc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/673M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Graphcore/bert-large-uncased were not used when initializing PipelinedBertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing PipelinedBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PipelinedBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PipelinedBertForQuestionAnswering were not initialized from the model checkpoint at Graphcore/bert-large-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = PipelinedBertForQuestionAnswering.from_pretrained(\"Graphcore/bert-large-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28020df5",
   "metadata": {},
   "source": [
    "We can now set up our pipelined execution by specifying which layers to put on each IPU, and passing it to the `parallelize` method that we defined above.\n",
    "\n",
    "We also call the `.half()` method to cast all the model weights to half-precision (FP16). The `.train()` sets the PyTorch model to training mode.\n",
    "\n",
    "If you unfamiliar with training in half precision on IPU, then we have a tutorial on [Half and Mixed Precision in Poptorch](https://github.com/graphcore/tutorials/tree/master/tutorials/pytorch/mixed_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82ac3ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:08.837702Z",
     "iopub.status.busy": "2022-08-04T18:54:08.837515Z",
     "iopub.status.idle": "2022-08-04T18:54:08.969777Z",
     "shell.execute_reply": "2022-08-04T18:54:08.968810Z",
     "shell.execute_reply.started": "2022-08-04T18:54:08.837681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Device Allocation --------------------\n",
      "Embedding  --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 1\n",
      "Encoder 3  --> IPU 1\n",
      "Encoder 4  --> IPU 1\n",
      "Encoder 5  --> IPU 2\n",
      "Encoder 6  --> IPU 2\n",
      "Encoder 7  --> IPU 2\n",
      "Encoder 8  --> IPU 3\n",
      "Encoder 9  --> IPU 3\n",
      "Encoder 10 --> IPU 3\n",
      "Encoder 11 --> IPU 4\n",
      "Encoder 12 --> IPU 4\n",
      "Encoder 13 --> IPU 4\n",
      "Encoder 14 --> IPU 5\n",
      "Encoder 15 --> IPU 5\n",
      "Encoder 16 --> IPU 5\n",
      "Encoder 17 --> IPU 6\n",
      "Encoder 18 --> IPU 6\n",
      "Encoder 19 --> IPU 6\n",
      "Encoder 20 --> IPU 7\n",
      "Encoder 21 --> IPU 7\n",
      "Encoder 22 --> IPU 7\n",
      "Encoder 23 --> IPU 7\n",
      "QA Outputs --> IPU 7\n"
     ]
    }
   ],
   "source": [
    "ipu_config = {\"layers_per_ipu\": [2,3,3,3,3,3,3,4],\n",
    "              \"recompute_checkpoint_every_layer\": True}\n",
    "\n",
    "model.parallelize(ipu_config).half().train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e67eeb",
   "metadata": {},
   "source": [
    "## 3. Runtime Configuration\n",
    "\n",
    "We will use a global batch size of 256 divided as such:\n",
    "- Micro batch size of 2 (the size of the batch passed to each replica)\n",
    "- Replication factor of 2 (the number of data parallel replicas, see the [Data Parallelism](#Data-Parallelism) section)\n",
    "- Gradient accumulation of 64 (the number of forward/backward passes performed per weight update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21dad837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:08.973354Z",
     "iopub.status.busy": "2022-08-04T18:54:08.973149Z",
     "iopub.status.idle": "2022-08-04T18:54:08.977264Z",
     "shell.execute_reply": "2022-08-04T18:54:08.976460Z",
     "shell.execute_reply.started": "2022-08-04T18:54:08.973332Z"
    }
   },
   "outputs": [],
   "source": [
    "global_batch_size = 256\n",
    "micro_batch_size = 2\n",
    "replication_factor = 2\n",
    "gradient_accumulation = int(global_batch_size / micro_batch_size / replication_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406381f",
   "metadata": {},
   "source": [
    "`device_iterations` is the number of batches the device should run before returning to the user. Increasing `device_iterations` can be more efficient because the loop runs on the IPU directly, reducing overhead costs. Please see the [documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/batching.html?highlight=device%20iterations#poptorch-options-deviceiterations) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad940a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:08.979762Z",
     "iopub.status.busy": "2022-08-04T18:54:08.979599Z",
     "iopub.status.idle": "2022-08-04T18:54:08.982473Z",
     "shell.execute_reply": "2022-08-04T18:54:08.981855Z",
     "shell.execute_reply.started": "2022-08-04T18:54:08.979746Z"
    }
   },
   "outputs": [],
   "source": [
    "device_iterations = 1\n",
    "samples_per_iteration = global_batch_size * device_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0a2d437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:08.984957Z",
     "iopub.status.busy": "2022-08-04T18:54:08.984614Z",
     "iopub.status.idle": "2022-08-04T18:54:08.987637Z",
     "shell.execute_reply": "2022-08-04T18:54:08.987074Z",
     "shell.execute_reply.started": "2022-08-04T18:54:08.984941Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c5ea6",
   "metadata": {},
   "source": [
    "We will now set the IPU configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eeaaf89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:08.990007Z",
     "iopub.status.busy": "2022-08-04T18:54:08.989850Z",
     "iopub.status.idle": "2022-08-04T18:54:08.997784Z",
     "shell.execute_reply": "2022-08-04T18:54:08.997223Z",
     "shell.execute_reply.started": "2022-08-04T18:54:08.989992Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = os.environ.get(\"CACHE_DIR\", \"exe_cache\")\n",
    "\n",
    "def ipu_training_options(gradient_accumulation, replication_factor, device_iterations):\n",
    "    opts = poptorch.Options()\n",
    "    opts.randomSeed(12345)\n",
    "    opts.deviceIterations(device_iterations)\n",
    "    \n",
    "    # Use Pipelined Execution\n",
    "    opts.setExecutionStrategy(\n",
    "        poptorch.PipelinedExecution(poptorch.AutoStage.AutoIncrement))\n",
    "\n",
    "    # Use Stochastic Rounding\n",
    "    opts.Precision.enableStochasticRounding(True)\n",
    "    \n",
    "    # Half precision partials for matmuls and convolutions\n",
    "    opts.Precision.setPartialsType(torch.float16)\n",
    "    \n",
    "    opts.replicationFactor(replication_factor)\n",
    "    \n",
    "    opts.Training.gradientAccumulation(gradient_accumulation)\n",
    "    \n",
    "    # Return all results from IPU to host\n",
    "    opts.outputMode(poptorch.OutputMode.All)\n",
    "    \n",
    "    # Cache compiled executable to disk\n",
    "    opts.enableExecutableCaching(CACHE_DIR)\n",
    "\n",
    "    # On-chip Replicated Tensor Sharding of Optimizer State\n",
    "    opts.TensorLocations.setOptimizerLocation(\n",
    "        poptorch.TensorLocationSettings()\n",
    "        # Optimizer state lives on IPU\n",
    "        .useOnChipStorage(True)\n",
    "        # Optimizer state sharded between replicas with zero-redundancy\n",
    "        .useReplicatedTensorSharding(True))\n",
    "\n",
    "    # Available Transient Memory For matmuls and convolutions operations\n",
    "    opts.setAvailableMemoryProportion({f\"IPU{i}\": mp\n",
    "                                       for i, mp in enumerate([0.08,0.28,0.32,0.32,0.36,0.38,0.4,0.1])})\n",
    "    \n",
    "    ## Advanced performance options ##\n",
    "\n",
    "    # Only stream needed tensors back to host\n",
    "    opts._Popart.set(\"disableGradAccumulationTensorStreams\", True)\n",
    "\n",
    "    # Copy inputs and outputs as they are needed\n",
    "    opts._Popart.set(\"subgraphCopyingStrategy\", int(popart.SubgraphCopyingStrategy.JustInTime))\n",
    "\n",
    "    # Parallelize optimizer step update\n",
    "    opts._Popart.set(\"accumulateOuterFragmentSettings.schedule\",\n",
    "                     int(popart.AccumulateOuterFragmentSchedule.OverlapMemoryOptimized))\n",
    "    opts._Popart.set(\"accumulateOuterFragmentSettings.excludedVirtualGraphs\", [\"0\"])\n",
    "\n",
    "    # Limit number of sub-graphs that are outlined (to preserve memory)\n",
    "    opts._Popart.set(\"outlineThreshold\", 10.0)\n",
    "\n",
    "    # Only attach to IPUs after compilation has completed.\n",
    "    opts.connectionType(poptorch.ConnectionType.OnDemand)\n",
    "    return opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ed5e1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.000002Z",
     "iopub.status.busy": "2022-08-04T18:54:08.999842Z",
     "iopub.status.idle": "2022-08-04T18:54:09.005409Z",
     "shell.execute_reply": "2022-08-04T18:54:09.004831Z",
     "shell.execute_reply.started": "2022-08-04T18:54:08.999986Z"
    }
   },
   "outputs": [],
   "source": [
    "train_opts = ipu_training_options(gradient_accumulation, replication_factor, device_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5f661",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dfe9e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.008186Z",
     "iopub.status.busy": "2022-08-04T18:54:09.008029Z",
     "iopub.status.idle": "2022-08-04T18:54:09.011601Z",
     "shell.execute_reply": "2022-08-04T18:54:09.010878Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.008167Z"
    }
   },
   "outputs": [],
   "source": [
    "from squad_preprocessing import PadCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf290b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.014101Z",
     "iopub.status.busy": "2022-08-04T18:54:09.013936Z",
     "iopub.status.idle": "2022-08-04T18:54:09.017040Z",
     "shell.execute_reply": "2022-08-04T18:54:09.016313Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.014085Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cbeac",
   "metadata": {},
   "source": [
    "We use the `poptorch.Dataloader` which is a drop-in replacement of `torch.Dataloader`, extending it with IPU specific options and asynchronous execution.\n",
    "\n",
    "Another small difference is the use of the `PadCollate` function. If `drop_last` option is false in a `DataLoader`, you may end up with a *remainder mini-batch* at the end of the epoch that is smaller than the other mini-batches. \n",
    "\n",
    "For a compiled device like IPU that would require a recompilation of the execution graph for that one mini-batch. In order to not lose any training examples, we can pad the remainder mini-batch with zeros and set the target values to a special value which will set the loss to 0 in those cases so they don't affect training. This way we have consistent mini-batch sizes and we can train on all the data.\n",
    "\n",
    "More information can be found in the [`poptorch.DataLoader` documentation.](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/batching.html#efficient-data-batching) and also in our [tutorial on efficient data loading.](https://github.com/graphcore/tutorials/tree/master/tutorials/pytorch/efficient_data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0adfc5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.019566Z",
     "iopub.status.busy": "2022-08-04T18:54:09.019394Z",
     "iopub.status.idle": "2022-08-04T18:54:09.025204Z",
     "shell.execute_reply": "2022-08-04T18:54:09.024531Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.019550Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:54:09.021] [poptorch::python] [warning] The number of elements in the dataset (88524) is not divisible by the number of elements processed per step (256) and drop_last=False. The last tensor will have a batch size of 204. To avoid having to handle this special case switch to drop_last=True\n"
     ]
    }
   ],
   "source": [
    "train_dl = poptorch.DataLoader(train_opts,\n",
    "                               train_dataset,\n",
    "                               batch_size=micro_batch_size,\n",
    "                               shuffle=True,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=PadCollate(samples_per_iteration,\n",
    "                                                     {\"input_ids\": 0,\n",
    "                                                      \"attention_mask\": 0,\n",
    "                                                      \"token_type_ids\": 0,\n",
    "                                                      \"start_positions\": sequence_length,\n",
    "                                                      \"end_positions\": sequence_length}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb9e04",
   "metadata": {},
   "source": [
    "We will use poptorch's version of the `AdamW` optimizer, its interface is the same as `AdamW` from `torch.optim`, but with some extra options.\n",
    "\n",
    "Please see the [`poptorch.optim` documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/overview.html#optimizers) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89372fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.027694Z",
     "iopub.status.busy": "2022-08-04T18:54:09.027525Z",
     "iopub.status.idle": "2022-08-04T18:54:09.033165Z",
     "shell.execute_reply": "2022-08-04T18:54:09.032433Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.027679Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    # Do not apply weight_decay for one-dimensional parameters\n",
    "    regularized_params = []\n",
    "    non_regularized_params = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            if len(param.shape) == 1:\n",
    "                non_regularized_params.append(param)\n",
    "            else:\n",
    "                regularized_params.append(param)\n",
    "\n",
    "    params = [\n",
    "        {\"params\": regularized_params, \"weight_decay\": 0.01},\n",
    "        {\"params\": non_regularized_params, \"weight_decay\": 0}\n",
    "    ]\n",
    "    optimizer = poptorch.optim.AdamW(params,\n",
    "                                     lr=1e-4,\n",
    "                                     weight_decay=0,\n",
    "                                     eps=1e-6,\n",
    "                                     bias_correction=True,\n",
    "                                     loss_scaling=64,\n",
    "                                     first_order_momentum_accum_type=torch.float16,\n",
    "                                     accum_type=torch.float16)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b25325d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.035704Z",
     "iopub.status.busy": "2022-08-04T18:54:09.035542Z",
     "iopub.status.idle": "2022-08-04T18:54:09.041407Z",
     "shell.execute_reply": "2022-08-04T18:54:09.040780Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.035688Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d315961",
   "metadata": {},
   "source": [
    "Now we create the function that will train our model on the IPU, then run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0683783a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.043659Z",
     "iopub.status.busy": "2022-08-04T18:54:09.043498Z",
     "iopub.status.idle": "2022-08-04T18:54:09.050647Z",
     "shell.execute_reply": "2022-08-04T18:54:09.050066Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.043642Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainer(model, opts, optimizer, train_dl, num_epochs):\n",
    "    num_steps = num_epochs * len(train_dl)\n",
    "    lr_scheduler = transformers.get_scheduler(\"cosine\", optimizer, 0.1 * num_steps, num_steps)\n",
    "    \n",
    "    # Wrap the pytorch model with poptorch.trainingModel\n",
    "    training_model = poptorch.trainingModel(model, train_opts, optimizer)\n",
    "    \n",
    "    # Compile model or load from executable cache\n",
    "    batch = next(iter(train_dl))\n",
    "    outputs = training_model.compile(batch[\"input_ids\"],\n",
    "                                     batch[\"attention_mask\"],\n",
    "                                     batch[\"token_type_ids\"],\n",
    "                                     batch[\"start_positions\"],\n",
    "                                     batch[\"end_positions\"])\n",
    "    # Training Loop\n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        train_iter = tqdm(train_dl)\n",
    "        for step, batch in enumerate(train_iter):\n",
    "            start_step = time.perf_counter()\n",
    "            \n",
    "            # This completes a forward+backward+weight update step\n",
    "            outputs = training_model(batch[\"input_ids\"],\n",
    "                                     batch[\"attention_mask\"],\n",
    "                                     batch[\"token_type_ids\"],\n",
    "                                     batch[\"start_positions\"],\n",
    "                                     batch[\"end_positions\"])\n",
    "\n",
    "            # Update the LR and update the poptorch optimizer\n",
    "            lr_scheduler.step()\n",
    "            training_model.setOptimizer(optimizer)\n",
    "            step_length = time.perf_counter() - start_step\n",
    "            step_throughput = samples_per_iteration / step_length\n",
    "            loss = outputs[0].mean().item()\n",
    "            train_iter.set_description(\n",
    "                f\"Epoch: {epoch} - \"\n",
    "                f\"Step: {step} - \"\n",
    "                f\"Loss: {loss:3.3f} - \"\n",
    "                f\"Throughput: {step_throughput:3.3f} seq/s\")\n",
    "    \n",
    "    # Detach the model from the device once training is over so the device is free to be reused for validation\n",
    "    training_model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fa169",
   "metadata": {},
   "source": [
    "Without a precompiled executable, compilation of this model may take around 10-15 minutes. \n",
    "\n",
    "In Section 3, we have set the [enableExecutableCaching](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/overview.html#precompilation-and-caching) so that a compiled executable will be searched for or writen to the directory. An executable can be loaded in this directory in order to skip compilation and proceed straight to training. \n",
    "\n",
    "Here, we have linked to the `.popef` files in `/graphcore/exe_cache`, so the model should compile in about one minute.\n",
    "\n",
    "Note that if you change the code so that other cache files are written, the cache directory might grow large and fill your storage as you recompile, so manage cache files accordingly. The code here by default writes on `/tmp` so it gets flushed upon shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c4d6815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.052974Z",
     "iopub.status.busy": "2022-08-04T18:54:09.052815Z",
     "iopub.status.idle": "2022-08-04T18:54:09.561718Z",
     "shell.execute_reply": "2022-08-04T18:54:09.560480Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.052958Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir /tmp/exe_cache\n",
    "!ln -s /graphcore/exe_cache/12985422070302931263.popef /tmp/exe_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a09347c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T18:54:09.564532Z",
     "iopub.status.busy": "2022-08-04T18:54:09.564356Z",
     "iopub.status.idle": "2022-08-04T19:07:28.079893Z",
     "shell.execute_reply": "2022-08-04T19:07:28.079008Z",
     "shell.execute_reply.started": "2022-08-04T18:54:09.564510Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph compilation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:40<00:00]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcd89bbbc2641c6ac4aaebb370ae975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8f24ab10b746658d56e196f5d3be42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b3876020094341bd5eb59eb53733fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d263c1f536594368ad0a577c8d904ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer(model, train_opts, optimizer, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4093fb",
   "metadata": {},
   "source": [
    "After training, we save the model weights to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43cbf9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:28.082489Z",
     "iopub.status.busy": "2022-08-04T19:07:28.082194Z",
     "iopub.status.idle": "2022-08-04T19:07:35.421136Z",
     "shell.execute_reply": "2022-08-04T19:07:35.420435Z",
     "shell.execute_reply.started": "2022-08-04T19:07:28.082455Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"checkpoints/squad_large_2x8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bfb59",
   "metadata": {},
   "source": [
    "## 5. Validation\n",
    "\n",
    "We will now take the model we just trained on the training data and run validation on the SQuAD validation dataset. The model will run on a 2-IPU pipeline that we will replicate 8 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdbb60f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:35.423468Z",
     "iopub.status.busy": "2022-08-04T19:07:35.423191Z",
     "iopub.status.idle": "2022-08-04T19:07:35.426088Z",
     "shell.execute_reply": "2022-08-04T19:07:35.425654Z",
     "shell.execute_reply.started": "2022-08-04T19:07:35.423450Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from squad_preprocessing import postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fae27b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:35.428313Z",
     "iopub.status.busy": "2022-08-04T19:07:35.428157Z",
     "iopub.status.idle": "2022-08-04T19:07:35.431391Z",
     "shell.execute_reply": "2022-08-04T19:07:35.430849Z",
     "shell.execute_reply.started": "2022-08-04T19:07:35.428298Z"
    }
   },
   "outputs": [],
   "source": [
    "micro_batch_size = 4\n",
    "replication_factor = 8\n",
    "global_batch_size = micro_batch_size * replication_factor\n",
    "device_iterations = 2\n",
    "samples_per_iteration = global_batch_size * device_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb75bbc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:35.433834Z",
     "iopub.status.busy": "2022-08-04T19:07:35.433676Z",
     "iopub.status.idle": "2022-08-04T19:07:35.438710Z",
     "shell.execute_reply": "2022-08-04T19:07:35.438013Z",
     "shell.execute_reply.started": "2022-08-04T19:07:35.433818Z"
    }
   },
   "outputs": [],
   "source": [
    "def ipu_validation_options(replication_factor, device_iterations):\n",
    "    opts = poptorch.Options()\n",
    "    opts.randomSeed(42)\n",
    "    opts.deviceIterations(device_iterations)\n",
    "\n",
    "    opts.setExecutionStrategy(\n",
    "        poptorch.PipelinedExecution(poptorch.AutoStage.AutoIncrement))\n",
    "\n",
    "    # Stochastic rounding not needed for validation\n",
    "    opts.Precision.enableStochasticRounding(False) \n",
    "\n",
    "    # Half precision partials for matmuls and convolutions\n",
    "    opts.Precision.setPartialsType(torch.float16)\n",
    "    \n",
    "    opts.replicationFactor(replication_factor)\n",
    "\n",
    "    # No gradient accumulation for Inference\n",
    "    opts.Training.gradientAccumulation(1)\n",
    "    \n",
    "    # Return all results from IPU\n",
    "    opts.outputMode(poptorch.OutputMode.All)\n",
    "    \n",
    "    # Cache compiled executable to disk\n",
    "    opts.enableExecutableCaching(CACHE_DIR)\n",
    "    \n",
    "    return opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2661a8d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:35.441224Z",
     "iopub.status.busy": "2022-08-04T19:07:35.440947Z",
     "iopub.status.idle": "2022-08-04T19:07:35.445285Z",
     "shell.execute_reply": "2022-08-04T19:07:35.444838Z",
     "shell.execute_reply.started": "2022-08-04T19:07:35.441205Z"
    }
   },
   "outputs": [],
   "source": [
    "val_opts = ipu_validation_options(replication_factor, device_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "282bf69d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:35.447328Z",
     "iopub.status.busy": "2022-08-04T19:07:35.447066Z",
     "iopub.status.idle": "2022-08-04T19:07:35.449589Z",
     "shell.execute_reply": "2022-08-04T19:07:35.449098Z",
     "shell.execute_reply.started": "2022-08-04T19:07:35.447311Z"
    }
   },
   "outputs": [],
   "source": [
    "ipu_config = {\"layers_per_ipu\": [11, 13],\n",
    "              \"recompute_checkpoint_every_layer\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851a340",
   "metadata": {},
   "source": [
    "Let's load the model weights we previously trained from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5552ff70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:35.451752Z",
     "iopub.status.busy": "2022-08-04T19:07:35.451492Z",
     "iopub.status.idle": "2022-08-04T19:07:37.675504Z",
     "shell.execute_reply": "2022-08-04T19:07:37.674713Z",
     "shell.execute_reply.started": "2022-08-04T19:07:35.451735Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PipelinedBertForQuestionAnswering.from_pretrained(\"checkpoints/squad_large_2x8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3eef9",
   "metadata": {},
   "source": [
    "We cast the model weights to half precision (FP16) and set the model to evaluation mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6a7fb38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:37.678071Z",
     "iopub.status.busy": "2022-08-04T19:07:37.677778Z",
     "iopub.status.idle": "2022-08-04T19:07:37.812352Z",
     "shell.execute_reply": "2022-08-04T19:07:37.811688Z",
     "shell.execute_reply.started": "2022-08-04T19:07:37.678050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Device Allocation --------------------\n",
      "Embedding  --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 0\n",
      "Encoder 3  --> IPU 0\n",
      "Encoder 4  --> IPU 0\n",
      "Encoder 5  --> IPU 0\n",
      "Encoder 6  --> IPU 0\n",
      "Encoder 7  --> IPU 0\n",
      "Encoder 8  --> IPU 0\n",
      "Encoder 9  --> IPU 0\n",
      "Encoder 10 --> IPU 0\n",
      "Encoder 11 --> IPU 1\n",
      "Encoder 12 --> IPU 1\n",
      "Encoder 13 --> IPU 1\n",
      "Encoder 14 --> IPU 1\n",
      "Encoder 15 --> IPU 1\n",
      "Encoder 16 --> IPU 1\n",
      "Encoder 17 --> IPU 1\n",
      "Encoder 18 --> IPU 1\n",
      "Encoder 19 --> IPU 1\n",
      "Encoder 20 --> IPU 1\n",
      "Encoder 21 --> IPU 1\n",
      "Encoder 22 --> IPU 1\n",
      "Encoder 23 --> IPU 1\n",
      "QA Outputs --> IPU 1\n"
     ]
    }
   ],
   "source": [
    "model.parallelize(ipu_config).half().eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47443bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:37.815874Z",
     "iopub.status.busy": "2022-08-04T19:07:37.815437Z",
     "iopub.status.idle": "2022-08-04T19:07:37.822829Z",
     "shell.execute_reply": "2022-08-04T19:07:37.822315Z",
     "shell.execute_reply.started": "2022-08-04T19:07:37.815852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:07:37.820] [poptorch::python] [warning] The number of elements in the dataset (10784) is not divisible by the number of elements processed per step (64) and drop_last=False. The last tensor will have a batch size of 32. To avoid having to handle this special case switch to drop_last=True\n"
     ]
    }
   ],
   "source": [
    "val_dl = poptorch.DataLoader(val_opts,\n",
    "                             validation_features.remove_columns(\n",
    "                                 ['example_id', 'offset_mapping']),\n",
    "                             batch_size=micro_batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False,\n",
    "                             collate_fn=PadCollate(samples_per_iteration,\n",
    "                                                   {\"input_ids\": 0,\n",
    "                                                    \"attention_mask\": 0,\n",
    "                                                    \"token_type_ids\": 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f9d476f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:37.825024Z",
     "iopub.status.busy": "2022-08-04T19:07:37.824765Z",
     "iopub.status.idle": "2022-08-04T19:07:37.830785Z",
     "shell.execute_reply": "2022-08-04T19:07:37.830306Z",
     "shell.execute_reply.started": "2022-08-04T19:07:37.825008Z"
    }
   },
   "outputs": [],
   "source": [
    "def validator(model, opts, val_dl):    \n",
    "    # Wrap the pytorch model with poptorch.inferenceModel for inference\n",
    "    inference_model = poptorch.inferenceModel(model, opts)\n",
    "    \n",
    "    raw_predictions = [[], []]\n",
    "    val_iter = tqdm(val_dl, desc=\"Validation\")\n",
    "    for step, batch in enumerate(val_iter):\n",
    "        start_step = time.perf_counter()\n",
    "        outputs = inference_model(batch[\"input_ids\"],\n",
    "                                  batch[\"attention_mask\"],\n",
    "                                  batch[\"token_type_ids\"])\n",
    "        step_length = time.perf_counter() - start_step\n",
    "        step_throughput = samples_per_iteration / step_length\n",
    "        raw_predictions[0].append(outputs[0])\n",
    "        raw_predictions[1].append(outputs[1])\n",
    "        val_iter.set_description(\n",
    "            f\"Step: {step} - throughput: {step_throughput:3.3f} samples/s\")\n",
    "    inference_model.detachFromDevice()\n",
    "    \n",
    "    raw_predictions[0] = torch.vstack(raw_predictions[0]).float().numpy()\n",
    "    raw_predictions[1] = torch.vstack(raw_predictions[1]).float().numpy()\n",
    "    return raw_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c26594",
   "metadata": {},
   "source": [
    "We loop over all the validation data examples and get the `raw_predictions` for the start and end positions of where the answer to the question lies in the text passage for each one.\n",
    "\n",
    "For validation, similar to training, we can load a precompiled execution to skip recompilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c43a0819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:37.833026Z",
     "iopub.status.busy": "2022-08-04T19:07:37.832763Z",
     "iopub.status.idle": "2022-08-04T19:07:38.471010Z",
     "shell.execute_reply": "2022-08-04T19:07:38.470144Z",
     "shell.execute_reply.started": "2022-08-04T19:07:37.833009Z"
    }
   },
   "outputs": [],
   "source": [
    "!ln -s /graphcore/exe_cache/10825557225208313664.popef /tmp/exe_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff68003a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:07:38.474443Z",
     "iopub.status.busy": "2022-08-04T19:07:38.474252Z",
     "iopub.status.idle": "2022-08-04T19:08:45.482601Z",
     "shell.execute_reply": "2022-08-04T19:08:45.481796Z",
     "shell.execute_reply.started": "2022-08-04T19:07:38.474421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901b5c0f13274826b42f65ae80ecf22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph compilation:   0%|          | 0/100 [00:00<?]\u001b[A\n",
      "Graph compilation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = validator(model, val_opts, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc526d8",
   "metadata": {},
   "source": [
    "We now post-process the raw predictions to the question answering task to get the best prediction that's valid for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd0f5ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:08:45.486796Z",
     "iopub.status.busy": "2022-08-04T19:08:45.486632Z",
     "iopub.status.idle": "2022-08-04T19:09:26.516151Z",
     "shell.execute_reply": "2022-08-04T19:09:26.515559Z",
     "shell.execute_reply.started": "2022-08-04T19:08:45.486779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 10570 example predictions split into 10784 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245fb063f32d47e39c9db5b3c0ba48f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"validation\"],\n",
    "                                               validation_features,\n",
    "                                               raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3426ec81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:09:26.531239Z",
     "iopub.status.busy": "2022-08-04T19:09:26.530970Z",
     "iopub.status.idle": "2022-08-04T19:09:29.768006Z",
     "shell.execute_reply": "2022-08-04T19:09:29.767313Z",
     "shell.execute_reply.started": "2022-08-04T19:09:26.531221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1db33864ee4e5fac7cba5f44b33bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be572b59730544cb961050963118b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 84.66414380321665, 'f1': 91.06543953018198}\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "formatted_predictions = [{\"id\": k, \"prediction_text\": v}\n",
    "                         for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]}\n",
    "              for ex in datasets[\"validation\"]]\n",
    "metrics = metric.compute(predictions=formatted_predictions, references=references)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846c248",
   "metadata": {},
   "source": [
    "We obtain here a good validation score for SQuADv1.\n",
    "\n",
    "| BERT-Large                             | Exact Match | F1 Score |\n",
    "|----------------------------------------|:-----------:|:--------:|\n",
    "| Reference (Devling et al. 2018)        | 84.1        | 90.9     |\n",
    "| IPU-POD16 with IPU pre-trained weights | 84.7        | 91.1     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b4335",
   "metadata": {},
   "source": [
    "## 6. Inference\n",
    "\n",
    "We can now use our fine-tuned model to answer questions. Let's start by defining a task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f63489fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:09:29.770402Z",
     "iopub.status.busy": "2022-08-04T19:09:29.770121Z",
     "iopub.status.idle": "2022-08-04T19:09:29.773061Z",
     "shell.execute_reply": "2022-08-04T19:09:29.772597Z",
     "shell.execute_reply.started": "2022-08-04T19:09:29.770371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define task\n",
    "question = \"What speed-up can one expect from using sequence packing for training BERT on IPU?\"\n",
    "answer_text = \"We find that at sequence length 512 padding tokens represent in excess of 50% of the Wikipedia\" \\\n",
    "              \"dataset used for pretraining BERT (Bidirectional Encoder Representations from Transformers).\" \\\n",
    "             \"Therefore by removing all padding we achieve a 2x speed-up in terms of sequences/sec.\" \\\n",
    "             \"To exploit this characteristic of the dataset,\" \\\n",
    "             \"we develop and contrast two deterministic packing algorithms.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6627d2d",
   "metadata": {},
   "source": [
    "Let's get the model inputs ready and create our model. We'll import the weights from the pre-trained, fine-tuned BERT model from the previous sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ceb1a496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:09:29.775354Z",
     "iopub.status.busy": "2022-08-04T19:09:29.775084Z",
     "iopub.status.idle": "2022-08-04T19:09:31.770010Z",
     "shell.execute_reply": "2022-08-04T19:09:31.769288Z",
     "shell.execute_reply.started": "2022-08-04T19:09:29.775337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "input_encoding = tokenizer.encode_plus((question, answer_text))\n",
    "\n",
    "# Extract inputs, add batch dimension\n",
    "input_tensor = torch.tensor(input_encoding[\"input_ids\"]).unsqueeze(0)\n",
    "attention_tensor= torch.tensor(input_encoding[\"attention_mask\"]).unsqueeze(0)\n",
    "token_types=torch.tensor(input_encoding[\"token_type_ids\"]).unsqueeze(0)\n",
    "    \n",
    "# Get model and load the fine-tuned weights\n",
    "model = transformers.BertForQuestionAnswering.from_pretrained(\"checkpoints/squad_large_2x8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e37d85",
   "metadata": {},
   "source": [
    "Optionally, instead of using the fine-tuned weights we saved in the previous section, you can download fine-tuned weights from the [Graphcore organisation on the HuggingFace Model Hub](https://huggingface.co/Graphcore). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e571ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:09:31.772292Z",
     "iopub.status.busy": "2022-08-04T19:09:31.772047Z",
     "iopub.status.idle": "2022-08-04T19:09:31.774715Z",
     "shell.execute_reply": "2022-08-04T19:09:31.774186Z",
     "shell.execute_reply.started": "2022-08-04T19:09:31.772274Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = transformers.BertForQuestionAnswering.from_pretrained(\"Graphcore/bert-large-uncased-squad11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f899b4",
   "metadata": {},
   "source": [
    "We can now solve the task and print the answer to the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efcd6c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:09:31.778023Z",
     "iopub.status.busy": "2022-08-04T19:09:31.777863Z",
     "iopub.status.idle": "2022-08-04T19:09:32.115070Z",
     "shell.execute_reply": "2022-08-04T19:09:32.114472Z",
     "shell.execute_reply.started": "2022-08-04T19:09:31.778007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What speed-up can one expect from using sequence packing for training BERT on IPU?\n",
      "Answer: 2x\n"
     ]
    }
   ],
   "source": [
    "# Solve task\n",
    "outputs = model(input_tensor, attention_tensor, token_types)\n",
    "\n",
    "# Extract answer\n",
    "answer_start, answer_stop = outputs.start_logits.argmax(), outputs.end_logits.argmax()\n",
    "answer_ids = input_tensor.squeeze()[answer_start:answer_stop + 1]\n",
    "answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids, skip_special_tokens=True)\n",
    "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "# Print results\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec71eec",
   "metadata": {},
   "source": [
    "**That's it for today folks. We learned how to fine-tune a BERT-Large model on the SQuADv1.1 dataset to get SOTA performance. Our model can now answer questions.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "008a66177cbc400587af50b64b22c8e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "00928119156c47b7b0651dd77a3b703d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "01143a3b887c456cb5ba6a5554fa1781": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0181aea86cf2426a8df2ef59eb006163": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "01ee47b5825f44b9a35b0f1a2d5f786d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0481fce1711a42419aaf7ceb6347ed9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9aa7e4a5d1bd44d28212358850a77f5b",
        "IPY_MODEL_2a2f4dde3e41485d98ae5142ecee12c9"
       ],
       "layout": "IPY_MODEL_5c8791000e03443fa70dec071b9db398"
      }
     },
     "066fa664116849098018e9baa066417d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_f262cd7b1a3c40bbbad84197e64de588",
       "max": 346,
       "style": "IPY_MODEL_9ab28f98f30e440aa49206cacace1931",
       "value": 86
      }
     },
     "07779d5402db4cf48b9f78b275ae8ef0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "07c9aed3f6ba41b4b17ea0f6e86477e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0808d61da7ab444288336a14f34d5bc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9a3803c989da4009ad588ca1283cf70e",
       "style": "IPY_MODEL_c681ea503e094c149100da1cbf572358",
       "value": " 3/3 [10:40&lt;00:00, 213.47s/it]"
      }
     },
     "0872f45312754a6dbe556f9bdac4d8f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "0920a4e34496461681c9376f086a4f02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b13343e39544e9881cf2e26f5ffba3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b8bfb3536424f1c8093ad658dd2349c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "0e89f27f9ade48b9876e365e8dc8de42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3b7a4b71108b4abdbc455be2b956b575",
        "IPY_MODEL_1c3a111026ef43c4a751de7bb0cf6b63",
        "IPY_MODEL_e1e5b2d4470c49478b1de0f8b8d512a4"
       ],
       "layout": "IPY_MODEL_fe16a84150d94088a7748459d74e7a57"
      }
     },
     "0f3d414b44974449b24c07cddd248e13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "1261d257152a40a18368f595466aac1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 2 - Step: 345 - Loss: 0.380 - Throughput: 556.949 seq/s: 100%",
       "layout": "IPY_MODEL_fce00d252d75456b9199a4313faf0963",
       "max": 346,
       "style": "IPY_MODEL_0f3d414b44974449b24c07cddd248e13",
       "value": 346
      }
     },
     "1344574ddf854e83a8f85ff6c1b69251": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_419c4e1e232d4b6b89d2e9edb83a3fc7",
       "style": "IPY_MODEL_f4666e5976f847538a3eb3de5de251dd",
       "value": " 86/346 [00:46&lt;02:17,  1.89it/s]"
      }
     },
     "14207f0293e741eaa1153902e55fb2e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a0330f3dd67346d0ad29977b1c930c5c",
       "max": 346,
       "style": "IPY_MODEL_72db2eeaaf7f4469898b0d345f125a1a",
       "value": 346
      }
     },
     "1434848ba8e34924a81900027b727f3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e6cdeccedbeb4ddca7cab4f0658850d0",
       "max": 346,
       "style": "IPY_MODEL_7bb5161067c440d6ab72ae1095b71407",
       "value": 346
      }
     },
     "14adb7851e6f49a0a5692bbb67365c9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "175769e2baa448fe9e1d0a6d0cd21f96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4613b1f9f4c4682ad7dd0bd99b64ccc",
       "style": "IPY_MODEL_cca7d495a9e24bcc9e2818500e465b91",
       "value": " 346/346 [07:23&lt;00:00,  1.28s/it]"
      }
     },
     "17831a84adfd4a3facbf706ef22f7316": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "17e50d4efe934e978da14755e29a6127": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18535685b6b3480393a392e5c004582b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_568c40a5d1ef47f6864f19d915ec20e0",
        "IPY_MODEL_7ed2a2aab41e4acd9dd1e3b3fa3731b4",
        "IPY_MODEL_6b359900df9a4c278ce08a408aa511cf"
       ],
       "layout": "IPY_MODEL_6dba9e1af5c44890b8b7d86130197d9a"
      }
     },
     "1c3a111026ef43c4a751de7bb0cf6b63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6e0e5239bdd64b6daf4f4e21162dfc3d",
       "max": 2,
       "style": "IPY_MODEL_51a1eb91ba6047138e3635987fd00f45",
       "value": 2
      }
     },
     "1d4ec2582038466b9c8b3c273b9b8f1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1d7981b404744ba4b791c98922818cd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1f111acf18bf4dc4a9728746be834514": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6306d37f90f845fdab4a15ac205627e0",
       "max": 10570,
       "style": "IPY_MODEL_86d9f694d52d4b6b89ba9aebe142d77c",
       "value": 10570
      }
     },
     "2353d9e0a42c42e8a1c8fef1f137aca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9a8efa64777841fa9a312d45fbe91ff1",
        "IPY_MODEL_0808d61da7ab444288336a14f34d5bc0"
       ],
       "layout": "IPY_MODEL_bb2ef00251204bddaaecac5555b9e81f"
      }
     },
     "2380d82578cc45a5ba4cf481f59354fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "24d0269086554bc7a14231dd7d03481a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "25edc3cac1fd427db24c82a0693cf7a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2669b96b18ab46a2a5e0736fef3d5f91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d660db84f39b4ca693057292e4d6e2a8",
       "style": "IPY_MODEL_5878ce9ce7124591b8935390d0b6968e",
       "value": " 346/346 [03:20&lt;00:00,  1.73it/s]"
      }
     },
     "269f1e466dcc41afa319def078b1045f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "29d8efdddad049f2b815f0e4e7a3bbaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2a2f4dde3e41485d98ae5142ecee12c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2b1e2a04955541e1ae33736b01b7c8c3",
       "style": "IPY_MODEL_aee35c3dde87426aaee859d7dab30775",
       "value": " 113/113 [04:58&lt;00:00,  2.64s/it]"
      }
     },
     "2b1e2a04955541e1ae33736b01b7c8c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2d7b09ef38c74d1484db4147a543a3b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d582c554820a44918b0cd2fa8009bce2",
       "max": 3,
       "style": "IPY_MODEL_63cc107be8f44e279c4299b7d17b4ffb",
       "value": 3
      }
     },
     "32bfe2d3c6fd4bc6b7c1ecc8b9f754d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b1ff12dbafba44d792d197a66f9741b7",
       "style": "IPY_MODEL_50611ea36f7842ca9dd42476ba0e768b",
       "value": " 346/346 [04:07&lt;00:00,  1.40it/s]"
      }
     },
     "32efc833332242d2b9bdc5732f3f83e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5abaedd8a0df4c5b93e37e1e1c4015fb",
       "style": "IPY_MODEL_d660f1b593e74ac695623b27234cfd14",
       "value": "Epoch: 1 - Step: 345 - Loss: 0.609 - Throughput: 631.668 seq/s: 100%"
      }
     },
     "3515d1d1982240f792fa7f4b8c9a4bca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37954b48eb164ffe8053637d740ec665": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c7f5d6085c264e66aca41b2941d66c08",
       "style": "IPY_MODEL_caa86e7c770c4b65979cb298694ecc3c",
       "value": "Epoch: 0 - Step: 85 - Loss: 1.309 - Throughput: 631.741 seq/s:  25%"
      }
     },
     "37efcdb2a015414397f9d7551c31bd69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_43e083c3b8214747ae10324e2b29ef12",
       "style": "IPY_MODEL_dfe6bcd0588846ed980238cce0ce3f23",
       "value": "100%"
      }
     },
     "394806f1ef1549019f5e98749e4942c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "3b7a4b71108b4abdbc455be2b956b575": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a416cc948ae445088d67e79fdef5de7f",
       "style": "IPY_MODEL_7abf963c624e403bb0db7464d1622555",
       "value": "100%"
      }
     },
     "3c65035318444b85bf2ca4602daec6b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3daf6e67d09444c8bb0dc4f6383431d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c8b69b41ac3946d49f9ded898ac17637",
        "IPY_MODEL_ef0f5be231f94dbeba93712230d0ad87"
       ],
       "layout": "IPY_MODEL_77f2d799553347bdb5d7977a2a870f24"
      }
     },
     "3e4f986cad4244f195cac0ce9a86f761": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3f50e999fa794c6fbdc6b4911051d16c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3faac7495c4c467da776fbf856c4618b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c440a5eef70547fdbdd428f07aa3ee68",
       "style": "IPY_MODEL_8e18e492dae0467cb9ebc44757c91fd6",
       "value": " 3/3 [09:31&lt;00:00, 189.92s/it]"
      }
     },
     "419c4e1e232d4b6b89d2e9edb83a3fc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "424fd49e58684ddf81b01383c45c2c35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c701f026d5cb415c90f45b15a19f8b0d",
        "IPY_MODEL_51fd1ad896b5445486cc114348bdccbf"
       ],
       "layout": "IPY_MODEL_83ab52267b0c45ed97ef1115182cd8c4"
      }
     },
     "43235a59a1f04f3b919ddfa67b993ec1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a6fd50dcdd8c4b3b99acb647debbf585",
        "IPY_MODEL_f03846bf22224128a81aaf092477426f"
       ],
       "layout": "IPY_MODEL_0b13343e39544e9881cf2e26f5ffba3c"
      }
     },
     "43431bea444146bc9612c4baa0464363": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a146b51061ae45ba9a99eb5149313a22",
        "IPY_MODEL_4a828a817d264c7dbd6ca1ffbea8b149"
       ],
       "layout": "IPY_MODEL_01143a3b887c456cb5ba6a5554fa1781"
      }
     },
     "43e083c3b8214747ae10324e2b29ef12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "449028d1c04c44f29d97b7291d88336a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "454af4b9e64b415a987450c467273256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "45bd07013d0148f1919d350b8794b383": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "483e09719495454eb0f9554d42772516": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_63fb867af23946af9f2ff7887197f4df",
        "IPY_MODEL_53e5ba5bba5c451c93d47af31d56bed0"
       ],
       "layout": "IPY_MODEL_07c9aed3f6ba41b4b17ea0f6e86477e5"
      }
     },
     "4892ddbb6757414fba7450c4d2895183": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "4a828a817d264c7dbd6ca1ffbea8b149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_17e50d4efe934e978da14755e29a6127",
       "style": "IPY_MODEL_cc9f73329ad44784936f9e39175e2762",
       "value": " 346/346 [05:06&lt;00:00,  1.13it/s]"
      }
     },
     "4f41a49093244e499f19edd0b4ce07b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4fffcf0014b243e389a16493818ae436": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "50611ea36f7842ca9dd42476ba0e768b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "519cd5a0c1b744ca82150c05427aa678": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "51a1eb91ba6047138e3635987fd00f45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "51fd1ad896b5445486cc114348bdccbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7629aaac2c0e402a9a6f85bb698ee85b",
       "style": "IPY_MODEL_5e90c8d3f1d7464f96d52b62093c742d",
       "value": " 10570/10570 [00:22&lt;00:00, 480.14it/s]"
      }
     },
     "5229f392494d4a8190aece85619fa3c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "53e5ba5bba5c451c93d47af31d56bed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f0558c88cfe40dbb463a84ad1ce2f3b",
       "style": "IPY_MODEL_008a66177cbc400587af50b64b22c8e4",
       "value": " 10570/10570 [00:22&lt;00:00, 473.43it/s]"
      }
     },
     "56545676fdee435a9862ac1da85e0618": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bd184564c54d475bb65c7cc429f284d4",
       "style": "IPY_MODEL_6db795a8ad43439e874755e4ea93fea7",
       "value": "Epochs:   0%"
      }
     },
     "5688c41f7eaf437081e532ba6c98d6eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_66e4b0e39fd940d586bc6cb05467dd5f",
       "max": 113,
       "style": "IPY_MODEL_1d4ec2582038466b9c8b3c273b9b8f1e",
       "value": 113
      }
     },
     "568c40a5d1ef47f6864f19d915ec20e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b3fdedd4fa4d42ccb734e5476b46f461",
       "style": "IPY_MODEL_00928119156c47b7b0651dd77a3b703d",
       "value": "Epoch: 2 - Step: 345 - Loss: 0.353 - Throughput: 571.998 seq/s: 100%"
      }
     },
     "573939d58d194a30b18ff15aed870bec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "57ced115d7474cd5b2bc902eb5d61f64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5878ce9ce7124591b8935390d0b6968e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5abaedd8a0df4c5b93e37e1e1c4015fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5c8791000e03443fa70dec071b9db398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e90c8d3f1d7464f96d52b62093c742d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6306d37f90f845fdab4a15ac205627e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "632e54ed92974d278c2e9200c8a630f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_acffceb0aa434c169979520f44582137",
        "IPY_MODEL_2d7b09ef38c74d1484db4147a543a3b2",
        "IPY_MODEL_3faac7495c4c467da776fbf856c4618b"
       ],
       "layout": "IPY_MODEL_a35d9b8305bb40a2a8a90f7e32bae8d8"
      }
     },
     "63cc107be8f44e279c4299b7d17b4ffb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "63fb867af23946af9f2ff7887197f4df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_86b64788c81042079a204561c008ce26",
       "max": 10570,
       "style": "IPY_MODEL_269f1e466dcc41afa319def078b1045f",
       "value": 10570
      }
     },
     "66e4b0e39fd940d586bc6cb05467dd5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6748f83e2145488bbd3e62e5beba7511": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "687c78cdd0e445389d54faea359c4ff3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_01ee47b5825f44b9a35b0f1a2d5f786d",
       "style": "IPY_MODEL_a2ceecf934a648858b7e86f5d0ca1548",
       "value": " 113/113 [02:57&lt;00:00,  1.57s/it]"
      }
     },
     "6a55285da8ba42a5b42433a9641f9688": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b72f3358acb34d979d11623b3407e5b3",
       "style": "IPY_MODEL_8efb053df531477da4af56ff6de17e33",
       "value": "Step: 112 - throughput: 3287.240 samples/s: 100%"
      }
     },
     "6b359900df9a4c278ce08a408aa511cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cf662aa184e043cb9616489a749f9d41",
       "style": "IPY_MODEL_25edc3cac1fd427db24c82a0693cf7a7",
       "value": " 346/346 [03:07&lt;00:00,  1.75it/s]"
      }
     },
     "6b5bc74901b34b15ae9b91bccd5f707d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a11cc6f332ee425f889b83dc4d47ddf4",
       "style": "IPY_MODEL_17831a84adfd4a3facbf706ef22f7316",
       "value": " 346/346 [03:12&lt;00:00,  1.91it/s]"
      }
     },
     "6db795a8ad43439e874755e4ea93fea7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6dba9e1af5c44890b8b7d86130197d9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e0e5239bdd64b6daf4f4e21162dfc3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6fb85aeae69f490da819efd2624435d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7269ab27965a4204a63d42dc3bc659ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "72db2eeaaf7f4469898b0d345f125a1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "731d640ba4444bd49b786b907eb37ad4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "74fe05961b97400588a29f7322e2db81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7629aaac2c0e402a9a6f85bb698ee85b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "76537c65be544568b91176fe115fdf4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "765e2d80436446dd9c3bbc1e68a7923e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ef246036865e45c3ba3637dc1ebbe561",
       "max": 2,
       "style": "IPY_MODEL_07779d5402db4cf48b9f78b275ae8ef0",
       "value": 2
      }
     },
     "76d1147989b0470c888d003311de0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "77f2d799553347bdb5d7977a2a870f24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7abf963c624e403bb0db7464d1622555": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7b6c6d3d77474913b0edc9f4db18f92b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7bb5161067c440d6ab72ae1095b71407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7ed2a2aab41e4acd9dd1e3b3fa3731b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_731d640ba4444bd49b786b907eb37ad4",
       "max": 346,
       "style": "IPY_MODEL_454af4b9e64b415a987450c467273256",
       "value": 346
      }
     },
     "83ab52267b0c45ed97ef1115182cd8c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8521a42dc4ea4a6998612bf0193b9ecc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_94c8d3393a8446919ebf351340bacabb",
        "IPY_MODEL_2669b96b18ab46a2a5e0736fef3d5f91"
       ],
       "layout": "IPY_MODEL_45bd07013d0148f1919d350b8794b383"
      }
     },
     "86b64788c81042079a204561c008ce26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "86d9f694d52d4b6b89ba9aebe142d77c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "88bad03b52904e7285df98b1f90268b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8bb6baf370674ce4aa7bd827e01eec43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_449028d1c04c44f29d97b7291d88336a",
       "style": "IPY_MODEL_ecdf7f81055c4e15ba236473d045f570",
       "value": " 2/2 [00:00&lt;00:00, 113.76it/s]"
      }
     },
     "8e18e492dae0467cb9ebc44757c91fd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8ea22108461f4b14a0604b3998a15d2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8efb053df531477da4af56ff6de17e33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8f0558c88cfe40dbb463a84ad1ce2f3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91c171a6bb0946b48a1e318a546671d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92f001bc0f8f4699b5b5ab32c5726d3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c38574303a314857af145c9314ce9f70",
        "IPY_MODEL_687c78cdd0e445389d54faea359c4ff3"
       ],
       "layout": "IPY_MODEL_b9e96a1b01da4c4ea96d325506b5a191"
      }
     },
     "94c8d3393a8446919ebf351340bacabb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 2 - Step: 345 - Loss: 0.354 - Throughput: 589.261 seq/s: 100%",
       "layout": "IPY_MODEL_ee8982c161d248d2b03cd7e64d09dcf6",
       "max": 346,
       "style": "IPY_MODEL_c19d37afbe1245d0b7eeded45c3dc8ba",
       "value": 346
      }
     },
     "9a3803c989da4009ad588ca1283cf70e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a64ac9a4c324ae789053bfbdac23803": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_519cd5a0c1b744ca82150c05427aa678",
       "style": "IPY_MODEL_a2cc96a7f2be4924b4eb3f2c5ca441b3",
       "value": " 0/3 [00:46&lt;?, ?it/s]"
      }
     },
     "9a8efa64777841fa9a312d45fbe91ff1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epochs: 100%",
       "layout": "IPY_MODEL_6748f83e2145488bbd3e62e5beba7511",
       "max": 3,
       "style": "IPY_MODEL_af1ce28acb6a4508834c321dc27345d3",
       "value": 3
      }
     },
     "9aa7e4a5d1bd44d28212358850a77f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Step: 112 - throughput: 3199.077 samples/s: 100%",
       "layout": "IPY_MODEL_5229f392494d4a8190aece85619fa3c9",
       "max": 113,
       "style": "IPY_MODEL_f5f7d6d815b64646bd467d53bed0365c",
       "value": 113
      }
     },
     "9ab28f98f30e440aa49206cacace1931": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9bfe384fbb324c5b98c58186e69eddb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c99a5d9125da4d7a80e14059376f754b",
        "IPY_MODEL_175769e2baa448fe9e1d0a6d0cd21f96"
       ],
       "layout": "IPY_MODEL_29d8efdddad049f2b815f0e4e7a3bbaa"
      }
     },
     "9cd8f1fd9295475fb7f0f8c72b88d39a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bded3a538b6440d78dd6a0b8700ae561",
        "IPY_MODEL_14207f0293e741eaa1153902e55fb2e6",
        "IPY_MODEL_ccd71a510a9949659751a3620d296894"
       ],
       "layout": "IPY_MODEL_74fe05961b97400588a29f7322e2db81"
      }
     },
     "a0330f3dd67346d0ad29977b1c930c5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a11cc6f332ee425f889b83dc4d47ddf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a146b51061ae45ba9a99eb5149313a22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 0 - Step: 345 - Loss: 0.791 - Throughput: 602.960 seq/s: 100%",
       "layout": "IPY_MODEL_91c171a6bb0946b48a1e318a546671d9",
       "max": 346,
       "style": "IPY_MODEL_e4b2f87a8b01461a8cf6478cc98091d2",
       "value": 346
      }
     },
     "a2cc96a7f2be4924b4eb3f2c5ca441b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a2ceecf934a648858b7e86f5d0ca1548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a35d9b8305bb40a2a8a90f7e32bae8d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a416cc948ae445088d67e79fdef5de7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a53b252f9ec04ebfac3ac8de73610a31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a575a994ef5a4b9998bc540532de6473": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_56545676fdee435a9862ac1da85e0618",
        "IPY_MODEL_c027c549f513403a8dd0e39497b0c3cc",
        "IPY_MODEL_9a64ac9a4c324ae789053bfbdac23803"
       ],
       "layout": "IPY_MODEL_aa45bce80ba04b66b99c79249bf05c0b"
      }
     },
     "a5b48da86e624d08b6b37d37ec2938b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_32efc833332242d2b9bdc5732f3f83e2",
        "IPY_MODEL_1434848ba8e34924a81900027b727f3f",
        "IPY_MODEL_6b5bc74901b34b15ae9b91bccd5f707d"
       ],
       "layout": "IPY_MODEL_0181aea86cf2426a8df2ef59eb006163"
      }
     },
     "a6fd50dcdd8c4b3b99acb647debbf585": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 1 - Step: 345 - Loss: 0.701 - Throughput: 576.474 seq/s: 100%",
       "layout": "IPY_MODEL_0920a4e34496461681c9376f086a4f02",
       "max": 346,
       "style": "IPY_MODEL_76d1147989b0470c888d003311de0685",
       "value": 346
      }
     },
     "a833ce9bfc554ef7ae2c462e896b1e47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aa45bce80ba04b66b99c79249bf05c0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "acffceb0aa434c169979520f44582137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a53b252f9ec04ebfac3ac8de73610a31",
       "style": "IPY_MODEL_14adb7851e6f49a0a5692bbb67365c9b",
       "value": "Epochs: 100%"
      }
     },
     "ad16ce91257f44eb8628fbac9eade9da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epochs: 100%",
       "layout": "IPY_MODEL_d174c9c67fec40f0bed694784a211a09",
       "max": 3,
       "style": "IPY_MODEL_0872f45312754a6dbe556f9bdac4d8f4",
       "value": 3
      }
     },
     "aee35c3dde87426aaee859d7dab30775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "af1ce28acb6a4508834c321dc27345d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "b1ff12dbafba44d792d197a66f9741b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b3fdedd4fa4d42ccb734e5476b46f461": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b4fd01884fde493999a6d2a7be7a9140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ad16ce91257f44eb8628fbac9eade9da",
        "IPY_MODEL_ff9adb8c41ce4e97bf8245f9dab30430"
       ],
       "layout": "IPY_MODEL_ec1436ebadf94df9a952badc66d9e51d"
      }
     },
     "b72f3358acb34d979d11623b3407e5b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9e96a1b01da4c4ea96d325506b5a191": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb2ef00251204bddaaecac5555b9e81f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb3aa322a3fb4027ac477afb4e12a637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e47ee37994894906a0c9ca66c6917a5c",
       "style": "IPY_MODEL_cc53dd8973d9476d85280ce0e40bfbfa",
       "value": "100%"
      }
     },
     "bbcc0cb21037499b8e8a4b7adf0b38e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_efc5029196ca434b869a31ae9c239b57",
       "style": "IPY_MODEL_88bad03b52904e7285df98b1f90268b3",
       "value": " 113/113 [02:25&lt;00:00,  9.70it/s]"
      }
     },
     "bc08f9d70ff948d5a43998903a474237": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd184564c54d475bb65c7cc429f284d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bded3a538b6440d78dd6a0b8700ae561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8ea22108461f4b14a0604b3998a15d2b",
       "style": "IPY_MODEL_3c65035318444b85bf2ca4602daec6b2",
       "value": "Epoch: 0 - Step: 345 - Loss: 0.741 - Throughput: 572.293 seq/s: 100%"
      }
     },
     "c027c549f513403a8dd0e39497b0c3cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_7269ab27965a4204a63d42dc3bc659ce",
       "max": 3,
       "style": "IPY_MODEL_1d7981b404744ba4b791c98922818cd3"
      }
     },
     "c19d37afbe1245d0b7eeded45c3dc8ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "c38574303a314857af145c9314ce9f70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Step: 112 - throughput: 3309.235 samples/s: 100%",
       "layout": "IPY_MODEL_57ced115d7474cd5b2bc902eb5d61f64",
       "max": 113,
       "style": "IPY_MODEL_0b8bfb3536424f1c8093ad658dd2349c",
       "value": 113
      }
     },
     "c3dd127febf143c9857bead90b7a7595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1261d257152a40a18368f595466aac1f",
        "IPY_MODEL_32bfe2d3c6fd4bc6b7c1ecc8b9f754d4"
       ],
       "layout": "IPY_MODEL_e54f4dab80634ab3ba228a78337fe16c"
      }
     },
     "c440a5eef70547fdbdd428f07aa3ee68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c5a251e538f844e7a2e202c652b3c235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c681ea503e094c149100da1cbf572358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c701f026d5cb415c90f45b15a19f8b0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_3e4f986cad4244f195cac0ce9a86f761",
       "max": 10570,
       "style": "IPY_MODEL_4892ddbb6757414fba7450c4d2895183",
       "value": 10570
      }
     },
     "c7b137b7e85d44f0aff6d434cbbf7df5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c5a251e538f844e7a2e202c652b3c235",
       "style": "IPY_MODEL_573939d58d194a30b18ff15aed870bec",
       "value": " 10570/10570 [00:21&lt;00:00, 496.49it/s]"
      }
     },
     "c7f5d6085c264e66aca41b2941d66c08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8b69b41ac3946d49f9ded898ac17637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 0 - Step: 345 - Loss: 0.778 - Throughput: 579.933 seq/s: 100%",
       "layout": "IPY_MODEL_a833ce9bfc554ef7ae2c462e896b1e47",
       "max": 346,
       "style": "IPY_MODEL_394806f1ef1549019f5e98749e4942c8",
       "value": 346
      }
     },
     "c99a5d9125da4d7a80e14059376f754b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 1 - Step: 345 - Loss: 0.664 - Throughput: 570.012 seq/s: 100%",
       "layout": "IPY_MODEL_e69da6300bf54664935e0fb187d7ccf1",
       "max": 346,
       "style": "IPY_MODEL_f8f79b3f429447499b402d770b144d1e",
       "value": 346
      }
     },
     "ca6ab92a0199442eb8c40b1c78995799": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6a55285da8ba42a5b42433a9641f9688",
        "IPY_MODEL_5688c41f7eaf437081e532ba6c98d6eb",
        "IPY_MODEL_bbcc0cb21037499b8e8a4b7adf0b38e9"
       ],
       "layout": "IPY_MODEL_e0df011be6ec4456a68130c56f513f99"
      }
     },
     "caa86e7c770c4b65979cb298694ecc3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cc53dd8973d9476d85280ce0e40bfbfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cc9f73329ad44784936f9e39175e2762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cca7d495a9e24bcc9e2818500e465b91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ccd71a510a9949659751a3620d296894": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e258e63ad0794bb88171a81134dd8b64",
       "style": "IPY_MODEL_dfa55558f3914ce0bb4c01ca468b43b6",
       "value": " 346/346 [03:12&lt;00:00,  1.74it/s]"
      }
     },
     "cf662aa184e043cb9616489a749f9d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d174c9c67fec40f0bed694784a211a09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d4613b1f9f4c4682ad7dd0bd99b64ccc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d582c554820a44918b0cd2fa8009bce2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d660db84f39b4ca693057292e4d6e2a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d660f1b593e74ac695623b27234cfd14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dfa55558f3914ce0bb4c01ca468b43b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dfe6bcd0588846ed980238cce0ce3f23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e0df011be6ec4456a68130c56f513f99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1e5b2d4470c49478b1de0f8b8d512a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3f50e999fa794c6fbdc6b4911051d16c",
       "style": "IPY_MODEL_24d0269086554bc7a14231dd7d03481a",
       "value": " 2/2 [00:00&lt;00:00, 110.21it/s]"
      }
     },
     "e1fe817426624b48a5a87ba446def36d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37954b48eb164ffe8053637d740ec665",
        "IPY_MODEL_066fa664116849098018e9baa066417d",
        "IPY_MODEL_1344574ddf854e83a8f85ff6c1b69251"
       ],
       "layout": "IPY_MODEL_76537c65be544568b91176fe115fdf4e"
      }
     },
     "e258e63ad0794bb88171a81134dd8b64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e47ee37994894906a0c9ca66c6917a5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4b2f87a8b01461a8cf6478cc98091d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "e54f4dab80634ab3ba228a78337fe16c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e69da6300bf54664935e0fb187d7ccf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6cdeccedbeb4ddca7cab4f0658850d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec1436ebadf94df9a952badc66d9e51d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ecdf7f81055c4e15ba236473d045f570": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ee8982c161d248d2b03cd7e64d09dcf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ef0f5be231f94dbeba93712230d0ad87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bc08f9d70ff948d5a43998903a474237",
       "style": "IPY_MODEL_7b6c6d3d77474913b0edc9f4db18f92b",
       "value": " 346/346 [04:56&lt;00:00,  1.17it/s]"
      }
     },
     "ef246036865e45c3ba3637dc1ebbe561": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "efc5029196ca434b869a31ae9c239b57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f03846bf22224128a81aaf092477426f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2380d82578cc45a5ba4cf481f59354fd",
       "style": "IPY_MODEL_feba0c0d24794b558734331478c2d2e5",
       "value": " 346/346 [06:32&lt;00:00,  1.14s/it]"
      }
     },
     "f262cd7b1a3c40bbbad84197e64de588": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4666e5976f847538a3eb3de5de251dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f5f7d6d815b64646bd467d53bed0365c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "f8bbcce113a647cb999fe5e8017e5e5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bb3aa322a3fb4027ac477afb4e12a637",
        "IPY_MODEL_765e2d80436446dd9c3bbc1e68a7923e",
        "IPY_MODEL_8bb6baf370674ce4aa7bd827e01eec43"
       ],
       "layout": "IPY_MODEL_4f41a49093244e499f19edd0b4ce07b9"
      }
     },
     "f8f79b3f429447499b402d770b144d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "fcd7540c0bf04eaa8be606396c899256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37efcdb2a015414397f9d7551c31bd69",
        "IPY_MODEL_1f111acf18bf4dc4a9728746be834514",
        "IPY_MODEL_c7b137b7e85d44f0aff6d434cbbf7df5"
       ],
       "layout": "IPY_MODEL_4fffcf0014b243e389a16493818ae436"
      }
     },
     "fce00d252d75456b9199a4313faf0963": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fe16a84150d94088a7748459d74e7a57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "feba0c0d24794b558734331478c2d2e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ff9adb8c41ce4e97bf8245f9dab30430": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3515d1d1982240f792fa7f4b8c9a4bca",
       "style": "IPY_MODEL_6fb85aeae69f490da819efd2624435d2",
       "value": " 3/3 [09:42&lt;00:00, 194.24s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
